---
# Prerequisites:
# $ pip install Pysphere
# mkisofs / on Mac via brew install cdrtools
# qemu-img
# ofvtool from vmware (this is a free tool)

# preparations for host to be provisioned happen on local machine - das sind im Prinzip alle tasks...!
- block:
  - include: "tools.yml"

  - name: Wait for vsphere to be available
    wait_for:
      host: '{{ vcenter_hostname }}'
      port: 80
      state: started
      timeout: 10

  - name: get facts from vsphere for guest (ignore failure)
    vsphere_guest:
      vcenter_hostname: "{{ vcenter_hostname }}"
      username: "{{ vcenter_user }}"
      password: "{{ vcenter_pass }}"
      validate_certs: no
      guest: "{{ inventory_hostname }}"
      vmware_guest_facts: yes
    register: guestfacts
    ignore_errors: true

  - name: fail if guest virtual machine already exists
    fail:
      msg: "A virtual machine on this host with the name {{ inventory_hostname }} already exists!"
    when:
      - guestfacts|succeeded
      - guestfacts.ansible_facts.hw_instance_uuid | match("^[a-z,0-9]{8}\-.*$")

  - name: Temp default temp folder to "/var/tmp/{{ role_path|basename }}/"
    set_fact:
      vmproim_tempfolder: "/var/tmp/{{ role_path|basename }}/"

  - name: Temp folder on MacOS or if TMPDIR variable is found
    set_fact:
      vmproim_tempfolder: "{{ lookup('env','TMPDIR') }}/{{ role_path|basename }}/"
    when: lookup('env','TMPDIR')

  - name: "create temp folder for staging of setup of vm images at {{ vmproim_tempfolder }}"
    file:
      path: "{{ vmproim_tempfolder }}"
      state: directory
      mode: 0755

  #- name: info temp folder will be deleted after run
  - debug: msg="info temp folder will be deleted after run"
    when: vmproim_delete_temp_folder == "yes"
    changed_when: true
    notify:
      - delete temp folder

  - name: download hdd image file for vm (can take very long!)
    get_url:
      url: "{{ vmproim_imagesource }}"
      dest: "{{ vmproim_tempfolder }}{{ vmproim_img_filename }}"
      checksum: "sha256:{{ vmproim_img_sha256 }}"
    when: vmproim_imagesource | match("^(http|ftp)s?.*")

  - name: copy hdd image for vm from given path
    copy:
      src: "{{ vmproim_imagesource }}"
      dest: "{{ vmproim_tempfolder }}{{ vmproim_img_filename }}"
    when: vmproim_imagesource | match("^\/.*\/?.*")

  - stat:
      path: "{{ vmproim_tempfolder }}{{ vmproim_img_filename }}"
      checksum_algorithm: sha256
    register: vmproim_img_filename_stat
    when: vmproim_imagesource | match("^\/.*\/?.*")

  - name: fail if checksum of copied image from path does not match
    fail:
      msg: "Checksum of the copied image source file differs from the requested checksum!"
    when:
      - vmproim_img_sha256 != vmproim_img_filename_stat.stat.checksum
      - vmproim_imagesource | match("^\/.*\/?.*")

  - name: convert to vmdk (if neccessary)
    shell: "qemu-img convert -f {{ vmproim_img_filename | regex_replace('(^.*\\.)(.+)$', '\\2') }} -O vmdk -o adapter_type=lsilogic,subformat=streamOptimized,compat6 -p {{ vmproim_img_filename }} {{ vmproim_vmdk }}"
    args:
      chdir: "{{ vmproim_tempfolder }}"
      creates: "{{ vmproim_vmdk }}"
    register: convertvmdk

  - name: copy generic ovf template to local staging directory
    template:
      src: ovf-template.ovf.j2
      dest: "{{ vmproim_tempfolder }}preconverted_{{ ofvtemplate_name }}"
    register: ofvtemplate

  - name: convert image for vmware with ofvtool
    shell: >
      ovftool
      --acceptAllEulas
      --noSSLVerify
      --skipManifestCheck
      --diskMode=thin
      --overwrite
      "preconverted_{{ ofvtemplate_name }}"
      "{{ ofvtemplate_name }}"
    args:
     chdir: "{{ vmproim_tempfolder }}"
    when: ofvtemplate.changed or convertvmdk.changed

  - name: create cloud init folder
    file:
      path: "{{ vmproim_tempfolder }}{{ inventory_hostname }}"
      state: directory
      mode: 0755

  - name: read this users ssh public key for cloud-init
    shell: cat ~/.ssh/id_rsa.pub
    sudo: no
    register: user_ssh_public_key

  - name: read this users username (running the deploy)
    local_action: command whoami
    sudo: no
    register: username_on_the_ansible_host

  - name: copy cloud-init user-data template for vm
    template:
      src: user-data.txt.j2
      dest: "{{ vmproim_tempfolder }}{{ inventory_hostname }}/user-data"
    register: userdata_task

  - name: copy cloud-init meta-data template for vm
    template:
      src: meta-data.txt.j2
      dest: "{{ vmproim_tempfolder }}{{ inventory_hostname }}/meta-data"
    register: metadata_task

  # userdata via cloud-config openstack - funktioniert leider nicht in der vm.
  #- file:
  #    path: "{{ vmproim_tempfolder }}{{ inventory_hostname }}/openstack/latest"
  #    state: directory
  #    recurse: yes
  #- name: copy cloud-init userdata openstack template for vm
  #  template:
  #    src: user-data.txt.j2
  #    dest: "{{ vmproim_tempfolder }}{{ inventory_hostname }}/openstack/latest/user-data"

  - name: create cd image for cloud-init (with mkisofs)
    shell: "mkisofs -output {{ cloudinit_iso }} -r -V cidata {{ inventory_hostname }}/"
    args:
      chdir: "{{ vmproim_tempfolder }}"
    #shell: "hdiutil makehybrid -iso -o {{ cloudinit_iso }} {{ inventory_hostname }}/"
    # auskommentiert: -V user-data // -V cidata
      #creates: "{{ cloudinit_iso }}"
    #when: metadata_task.changed or userdata_task.changed
    #ansible_os_family == 'Darwin'


  # run this whole block via:
  delegate_to: localhost
  tags:
    - prepare

- block:
  - name: transfer vm to host using VMWare ovftool
    shell: >
      ovftool
      --acceptAllEulas
      --noSSLVerify
      --skipManifestCheck
      --X:logFile="{{ vmproim_tempfolder }}deploy_ovftool_{{ inventory_hostname }}.log"
      --diskMode=thin
      --diskSize:template2,11="{{ disk * 1024 * 1024 }}"
      --name="{{ inventory_hostname }}"
      --datastore="{{ vmproim_datastore }}"
      --network="{{ vmproim_network }}"
      "{{ vmproim_tempfolder }}{{ ofvtemplate_name }}"
      "vi://{{ vcenter_user | urlencode }}:{{ vcenter_pass | urlencode }}@{{ vcenter_hostname }}:443"
    register: deploy_ovf_result
    # use --overwrite option if you want to overwrite the vm on the host,
    #       else it fails if the host already exists

  - name: copy cloud-init iso to hosting machine
    vsphere_copy:
      host: "{{ vcenter_hostname }}"
      login: "{{ vcenter_user }}"
      password: "{{ vcenter_pass }}"
      src: "{{ vmproim_tempfolder }}{{ cloudinit_iso }}"
      datacenter: "{{ vmproim_datacenter }}"
      datastore: "{{ vmproim_datastore }}"
      path: "/{{ inventory_hostname }}/{{ cloudinit_iso }}"
      validate_certs: no

  - name: reconfigure VM on vSphere
    vsphere_guest:
      vcenter_hostname: "{{ vcenter_hostname }}"
      username: "{{ vcenter_user }}"
      password: "{{ vcenter_pass }}"
      validate_certs: no
      guest: "{{ inventory_hostname }}"
      state: reconfigured
      vm_extra_config:
        notes: "{{ vmproim_notes }}"
    #  vm_disk:
    #    disk1:
    #      size_gb: "{{ disk }}"
    #      type: thin
    #      datastore: "{{ vmproim_datastore }}"
      vm_nic:
        nic1:
          type: "{{ vmproim_nictype }}"
          network: "{{ vmproim_network }}"
          network_type: standard
      vm_hardware:
        memory_mb: "{{ memory }}"
        num_cpus: "{{ cpucount }}"
        osid: "{{ osid }}"
        scsi: paravirtual
        vm_cdrom:
          type: "iso"
          iso_path: "{{ vmproim_datastore }}/{{ inventory_hostname }}/{{ cloudinit_iso }}"
          state: connected
      esxi:
        datacenter: "{{ vmproim_datacenter }}"
        hostname: "{{ vcenter_esxi }}"

  - name: power on vm on vSphere
    vsphere_guest:
      vcenter_hostname: "{{ vcenter_hostname }}"
      username: "{{ vcenter_user }}"
      password: "{{ vcenter_pass }}"
      validate_certs: no
      guest: "{{ inventory_hostname }}"
      state: powered_on
      esxi:
        datacenter: "{{ vmproim_datacenter }}"
        hostname: "{{ vcenter_esxi }}"

  # run this whole block via:
  delegate_to: localhost
  tags:
    - provision

- block:
  - name: set ip or hostname to ping
    set_fact:
      ping_hostname: "{% if ipv4 | ipv4 %}{{ ipv4 }}{% else %}{{ inventory_hostname }}{% endif %}"

  - name: "Wait for the post-install SSH to become available at {{ ping_hostname }}"
    wait_for:
      host: '{{ ping_hostname }}'
      port: 22
      state: started
      timeout: 300

  - name: wait for the vm to work init...
    pause:
      seconds: 30

  - name: Wait for the host to become unavailable = finished init
    wait_for:
      host: '{{ ping_hostname }}'
      port: 22
      state: stopped
      timeout: 300

  # warten, falls der host einige Zeit zum herunterfahren ben√∂tigt
  - pause:
      seconds: 10

  - name: reconfigure VM on vSphere - detach cd image
    vsphere_guest:
      vcenter_hostname: "{{ vcenter_hostname }}"
      username: "{{ vcenter_user }}"
      password: "{{ vcenter_pass }}"
      validate_certs: no
      guest: "{{ inventory_hostname }}"
      state: reconfigured
      vm_hardware:
        vm_cdrom:
          type: "iso"
          iso_path: "{{ vmproim_datastore }}/{{ inventory_hostname }}/{{ cloudinit_iso }}"
          state: disconnected
      esxi:
        datacenter: "{{ vmproim_datacenter }}"
        hostname: "{{ vcenter_esxi }}"

  - name: power on vm on vSphere
    vsphere_guest:
      vcenter_hostname: "{{ vcenter_hostname }}"
      username: "{{ vcenter_user }}"
      password: "{{ vcenter_pass }}"
      validate_certs: no
      guest: "{{ inventory_hostname }}"
      state: powered_on
      esxi:
        datacenter: "{{ vmproim_datacenter }}"
        hostname: "{{ vcenter_esxi }}"

  - name: Wait for the post-reboot SSH to become available
    wait_for:
      host: '{{ ping_hostname }}'
      port: 22
      state: started
      timeout: 300
      delay: 2

  # workaround: wait a long time because the the host will regenerate ssh keys after beeing startet up again so the first key that would be used would not be used afterwards by itself thus producing the problem of not being able to login...

  # via https://github.com/ansible-provisioning/ansible-provisioning/blob/master/README.md
  ### Revoke any existing host keys for this server (should become a separate ansible module to avoid conflicts)
  - name: Revoke any existing host keys for this server by hostname
    command: ssh-keygen -R {{ inventory_hostname_short }}

  # herausfinden der IP zum entfernen dieser aus den known_hosts
  - command: "dig +short {{ inventory_hostname }}"
    changed_when: false
    register: dig_output

  - set_fact:
      looked_up_ips: "{{ dig_output.stdout_lines }}"

  - debug: msg="found ip {{ item }}"
    with_items:
      - "{{ looked_up_ips }}"
      - "{{ ping_hostname }}"

  - name: Revoke any existing host keys for this server by ip address
    command: "ssh-keygen -R {{ item }}"
    with_items:
      - "{{ looked_up_ips }}"
      - "{{ ping_hostname }}"

  - name: ensure the newly created host is an ssh known host (unsecure for MITM!!)
    known_hosts:
      #path: /etc/ssh/ssh_known_hosts
      name: "{{ ping_hostname }}"
      key: "{{ lookup('pipe', 'ssh-keyscan -t rsa {{ ping_hostname }}') }}"

  # run this whole block via:
  delegate_to: localhost
  sudo: no
  tags:
    - reconfigure
